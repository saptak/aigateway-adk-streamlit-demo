apiVersion: gateway.envoyproxy.io/v1alpha1
kind: AIGateway
metadata:
  name: financial-advisor-gateway
spec:
  listeners:
    - name: main
      port: 9000
      protocol: http
  rateLimits:
    - name: token-based-limit
      # Set token limits for different API providers
      tokenLimits:
        - provider: openai
          inputTokensPerSecond: 5000
          outputTokensPerSecond: 2500
        - provider: anthropic
          inputTokensPerSecond: 5000
          outputTokensPerSecond: 2500
        - provider: google
          inputTokensPerSecond: 5000
          outputTokensPerSecond: 2500
  routes:
    - name: investment-advisor
      matches:
        - path: /v1/investment
      backends:
        - name: openai-investment-backend
          priority: 1
          provider:
            openai:
              model: gpt-4-1106-preview
              temperature: 0.3
              maxOutputTokens: 1024
        - name: anthropic-investment-backend
          priority: 2
          provider:
            anthropic:
              model: claude-3-opus-20240229
              temperature: 0.3
              maxOutputTokens: 1024
      securityPolicy:
        authentication:
          jwtProvider:
            issuer: "fintech-demo-issuer"
            audiences: ["financial-advisor-app"]
            remoteJwks:
              uri: "https://example.com/.well-known/jwks.json"
              httpTimeout: 5s
              cacheDuration: 300s
    
    - name: loan-calculator
      matches:
        - path: /v1/loan
      backends:
        - name: openai-calculation-backend
          priority: 1
          provider:
            openai:
              model: gpt-4-1106-preview
              temperature: 0.1
              maxOutputTokens: 512
    
    - name: customer-service
      matches:
        - path: /v1/customer
      backends:
        - name: anthropic-service-backend
          priority: 1
          provider:
            anthropic:
              model: claude-3-sonnet-20240229
              temperature: 0.7
              maxOutputTokens: 1024
    
    - name: default-route
      matches:
        - path: /v1/*
      backends:
        - name: default-backend
          priority: 1
          provider:
            google:
              model: gemini-1.5-pro
              temperature: 0.4
              maxOutputTokens: 1024
  
  observability:
    logging:
      level: info
      format: json
      destination:
        stdout: {}
    metrics:
      prometheus:
        scrape: true
        path: /metrics
        port: 9901
  
  security:
    cors:
      allowOrigins:
        - "http://localhost:8501"  # Streamlit app
      allowMethods:
        - GET
        - POST
      allowHeaders:
        - Authorization
        - Content-Type
      exposeHeaders:
        - X-RateLimit-Limit
        - X-RateLimit-Remaining
      maxAge: 86400
